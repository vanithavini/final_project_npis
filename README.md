## ğŸ“° News Popularity Intelligence System using Transformer-Based Deep Learning ##

## ğŸ“Œ Project Overview
- Digital news platforms must prioritize articles before real-world engagement signals (clicks, shares, impressions, CTR) become    available.
- This project builds an Explainable Transformer-Based Intelligence System that predicts the popularity potential of news articles   using:
    - Transformer-based semantic representation (DistilBERT)
    - Linguistic proxy intelligence signals
    - Weighted editorial scoring framework
    - Explainable AI (XAI) reasoning layer
    - Priority-based ranking engine
    - Interactive Streamlit dashboard
- Unlike traditional supervised models, this system treats popularity as a latent variable inferred through proxy indicators, making it a weakly supervised intelligence framework.

## ğŸ§© Problem Statement
- Digital news platforms must decide which articles to highlight, promote, or deprioritize at the time of publishing. However, real-world popularity indicators such as clicks, shares, and impressions are not immediately available.
- The objective of this project is to design and implement a Transformer-based News Popularity Intelligence System that:
    * Learns deep semantic representations of news articles using transfer learning
    * Infers relative popularity potential directly from text
    * Ranks and scores articles based on predicted attention likelihood
    * Provides explainable insights to support editorial decision-making

## ğŸ— System Architecture
The system follows an enterprise-layered AI architecture:

Data Layer
   â†“
NLP Representation Layer (DistilBERT)
   â†“
Signal Intelligence Layer
   â†“
Weighted Scoring Engine
   â†“
Decision & Explainability Layer
   â†“
Streamlit Intelligence Dashboard

# ğŸ”µ Data Layer
Raw news dataset
Title + Description extraction
Text preprocessing

# ğŸŸ¢ NLP Representation Layer
Text cleaning
DistilBERT embeddings
Semantic vector representation

# ğŸŸ  Intelligence & Signal Layer
Proxy signals used to estimate popularity:
Emotional Intensity
Urgency
Lexical Diversity
Readability
Subjectivity
Length Signal

# ğŸŸ£ Decision Layer
Weighted aggregation
Popularity percentage score
Priority classification (High / Medium / Low)
Article ranking
Explainability engine

## ğŸ§  Scoring Logic
Final popularity score is computed as:

Final Score =
    (Emotion * 0.25) +
    (Urgency * 0.20) +
    (Lexical Diversity * 0.15) +
    (Readability * 0.15) +
    (Length * 0.10) +
    (Subjectivity * 0.15)

The weights reflect editorial influence assumptions and can be tuned.

## ğŸ” Explainability Framework
The Explainability Engine provides:
Contribution breakdown per signal
Top contributing factors
Transparent scoring logic
Contribution formula:
    Contribution = Signal Score Ã— Weight Ã— 100
This ensures interpretability and trust in decision-making.

## ğŸ“Š Features
âœ” Transformer-based semantic analysis
âœ” Weakly supervised popularity inference
âœ” Modular AI architecture
âœ” Weighted editorial intelligence
âœ” Explainable AI (XAI)
âœ” Article ranking engine
âœ” Interactive Streamlit dashboard
âœ” Architecture visualization using Graphviz

## ğŸ—‚ Project Structure
news-popularity-intelligence/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚    â”œâ”€â”€ news.csv
â”‚   â””â”€â”€ processed/
â”‚        â”œâ”€â”€ embeddings_chunks
â”‚        â”œâ”€â”€ news_cleaned.csv
â”‚        â”œâ”€â”€ news_embeddings.npy
â”‚        â”œâ”€â”€ news_popularity_scored.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_raw_data_sanity_check.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â”œâ”€â”€ 03_bert_representation_learning.ipynb
â”‚   â”œâ”€â”€ 04_popularity_scoring.ipynb
â”‚   â”œâ”€â”€ 05_article_ranking.ipynb
â”‚   â””â”€â”€ 06_explainability_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ embedding_generator.py
â”‚   â”œâ”€â”€ explainability_engine.py
â”‚   â”œâ”€â”€ popularity_scorer.py
â”‚   â”œâ”€â”€ popularity_signals.py
â”‚   â”œâ”€â”€ ranking_engine.py
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ” Module-wise Description
# Module 1
  1.1 --> raw_data_sanity_check.ipynb    # Convert raw, messy news text into a clean, model-ready textual input while: Preserving
  1.2 --> data_preprocessing.py         semantics, avoiding over-processing, maintaining traceability for explainability. EDA is used
  1.3 --> eda.ipynb                     for assumption validation rather than correlation analysis because of no labels exists.

# Module 2
  2.1 --> embedding_generator.py                # Convert each news article into a dense semantic vector. Capture - emotion, urgency, 
  2.2 --> bert_representation_learning.ipynb    semantics, narrative style. Save the embeddings for downstream scoring and ranking.

# Module 3
  3.1 --> popularity_signals.py          # We designed a weakly-supervised popularity scoring engine that infers attention likelihood
  3.2 --> popularity_scorer.py           using editorial signals.The system normalize scores into 0-100 scale & classifies articles 
  3.3 --> popularity_scoring.ipynb       into priority tiers, enabling explainable & label-free ranking. Popularity is latent. we 
                                         infer it using attention-related signals.

# Module 4
  4.1 --> ranking_engine.py               # Rank articles using BERT embeddings(semantic strength) & Popularity Score(attention
  4.2 --> article_ranking.ipynb            likelihood). Generate clear,human-readable explanations.Explainability is achieved by 
  4.3 --> explainability_engine.py         decomposing the popularity score into weighted linguistic signal contributions, enabling
  4.4 --> explainability_analysis.ipynb    transparent editorial reasoning.

# Module 5
  Streamlit app --> app.py                # We implemented comparitive explainability by visualizing signal-level contribution 
                                           differences between emotionally intense and neutral articles.

## ğŸš€ Installation & Setup
1ï¸âƒ£ Clone Repository
    git clone 

2ï¸âƒ£ Create Virtual Environment
    python -m venv .venv
    .venv\Scripts\activate      

3ï¸âƒ£ Install Dependencies
    pip install -r requirements.txt

â–¶ï¸ Run the Application
    streamlit run app.py

The dashboard will open in your browser.

## ğŸ“¦ Dependencies
Key dependencies used:
- Data Handling
        pandas
        numpy
- NLP & Linguistic Analysis
        nltk
        textblob
        textstat
- Transformer Models
        torch
        transformers
        sentencepiece
- Machine Learning Utilities
        scikit-learn
- Visualization
        matplotlib
        seaborn
        graphviz
- Deployment
        streamlit

## ğŸ“ˆ Example Use Case
# Article 1
"Breaking: Massive earthquake devastates coastal city"
    High emotion
    High urgency
    High popularity score

# Article 2
"Quarterly economic statistics report released"
    Low emotion
    Low urgency
    Lower popularity score

The system ranks  Article 1 higher due to stronger proxy signals.

## ğŸ¯ Why This Project Is Unique
- Does not rely on labeled popularity data
- Models popularity as a latent variable
- Combines Transformer NLP + heuristic intelligence
- Fully explainable scoring framework
- Enterprise-style layered architecture
- Deployable AI dashboard

## ğŸ¢ Industry Applications
- Digital news platforms
- Editorial prioritization systems
- Content recommendation engines
- Media analytics platforms
- Publishing workflow automation

## ğŸ”® Future Improvements
- Fine-tuned Transformer model for engagement prediction
- Reinforcement learning for weight optimization
- Real-time API deployment
- A/B testing integration
- User personalization layer
- Automated weight learning via weak supervision

